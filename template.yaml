theme: default # default || dark
organization: Roblox, University of Maryland
twitter: '@deedzgao'
title: 'An Intrinsic Vector Heat Network'
journal: "ICML 2024"
resources:
  paper: https://arxiv.org/pdf/2406.09648v1
  arxiv: https://arxiv.org/abs/2406.09648v1/
  code: https://github.com/gaoalexander/vector-heat-net/
description: project page for an-intrinsic-vector-heat-network

image: https://gaoalexander.github.io/vector-heat-network/assets/teaser_v2.png
url: https://gaoalexander.github.io/vector-heat-network
speakerdeck: # speakerdeck slide ID
authors:
  - name: Alexander Gao
    affiliation: [1, 2]
    url: http://gaoalexander.github.io/
    position: intern
  - name: Maurice Chu
    affiliation: [1]
    position: Researcher
    url: https://www.linkedin.com/in/maurice-chu-1ab3731a/
  - name: Mubbasir Kapadia
    affiliation: [1]
    position: Researcher
    url: https://scholar.google.com/citations?user=xhkzmycAAAAJ&hl=en/
  - name: Ming C. Lin
    affiliation: [1]
    position: Researcher
    url: https://www.cs.umd.edu/~lin/
  - name: Hsueh-Ti Derek Liu
    affiliation: [1]
    position: Researcher
    url: https://www.dgp.toronto.edu/~hsuehtil/
affiliations:
  - Roblox
  - University of Maryland, College Park
meta:
  - ' '
bibtex: >
  @article{gao2024vectorheatnet,
    author    = {Alexander Gao and Maurice Chu and Mubbsir Kapadia and Ming C. Lin and Hsueh-Ti Derek Liu},
    title     = {An Intrinsic Vector Heat Network},
    journal   = {International Conference on Machine Learning (ICML)},
    year      = {2024},
    keywords  = {Differential Geometry, Geometric Deep Learning, Graph Neural Networks, Vector Fields},
    url       = {https://arxiv.org/abs/2406.09648v1},
  }

teaser: teaser_v2.png
abstract: |
    Vector fields are widely used to represent and model flows for many science and engineering applications.  This paper introduces a novel neural network architecture for learning tangent vector fields that are intrinsically defined on manifold surfaces embedded in 3D.  Previous approaches to learning vector fields on surfaces treat vectors as multi-dimensional scalar fields, using traditional scalar-valued architectures to process channels individually, thus fail to preserve fundamental intrinsic properties of the vector field.  The core idea of this work is to introduce a trainable vector heat diffusion module to spatially propagate vector-valued feature data across the surface, which we incorporate into our proposed architecture that consists of vector-valued neurons.  Our architecture is invariant to rigid motion of the input, isometric deformation, and choice of local tangent bases, and is robust to discretizations of the surface.  We evaluate our Vector Heat Network on triangle meshes, and empirically validate its invariant properties.  We also demonstrate the effectiveness of our method on the useful industrial application of quadrilateral mesh generation.

body:
  - - title: Neural Network Architecture
    text: |
      <div>
          <img src="assets/architecture.png">
        </div>
      </div>

      Our vector-valued neural network for processing tangent vector fields utilizes vector-valued neurons with vector operations (e.g., parallel transport and the vector heat equation). Maintaining the vector nature of our data throughout results in an architecture that is invariant to isometries, rigid transformations, and the choice of tangent bases (see below).
      The input to our network is a set of tangent vectors defined on the vertices of a surface triangle mesh. A Vector Heat Network consists of several blocks of learned heat diffusion to harness local information, and vector MLPs to increase the expressiveness. The output is a set of tangent vector fields defined on vertices. These output fields could be regular tangent vectors or tangent vectors with N rotational symmetry defined on the tangent plane. In this section, we will illustrate individual components of our Vector Heat Network in more details.

  - title: Invariances
    text: |
      Our architecture possesses several fundamental invariances, which we highlight and empirically validate here, distinguishing it from the scalar-valued approach of (Dielen et al., 2021). These invariances arise from the fact that all of our operations (gradient, heat diffusion, and the per-vertex linear layer) are intrinsic, which implies that our architecture is invariant to how the mesh sits in the space.
      <div class="uk-child-width-1-1@m" uk-grid>

      <div class="uk-child-width-1-1@m" uk-grid>
        <div>
          <img src="assets/invariance_local_basis.png">
        </div>
      </div>

      <div>
          <img src="assets/invariance_rigid_motions.png">
        </div>
      </div>

      <div>
          <img src="assets/isometry.png">
        </div>
      </div>

  - title: Quadrilateral Meshing Application
    text: |
      Here's our demo text showcasing the power of markdown and KaTeX integration!
      Markdown allows you to easily format text using simple syntax.
      - **bold**
      - *italic*
      - `inline code`.

      You can also create headings of various levels:
      # Heading Level 1
      ## Heading Level 2
      ### Heading Level 3
      #### Heading Level 4
      Markdown allows you to create tables like the following:
      ### Fictitious AI Benchmark Results
      | Model Name          | Accuracy (%) | Inference Time (ms) |
      |---------------------|--------------|---------------------|
      | TransGPT-XT         | 96.3         | $\infty$                 |
      | GigaBERT Prime      | 94.7         | 9.5                 |
      | MegaLSTM-Pro        | 92.5         | 10.1                |
      | UltraTransformer    | 97.1         | 7.8                 |
      | **QuantumDNN-ALPHA**    | 95.8         | 8.5             |

      Of course, you can also directly write tables in HTML if needed. For more details, refer to the [UIKit Table documentation](https://getuikit.com/docs/table).

      <div class="uk-overflow-auto uk-width-1-1">
        <table class="uk-table uk-table-small uk-text-small uk-table-divider">
          <thead>
            <tr>
              <th>Model Name</th>
              <th>Accuracy (%)</th>
              <th>Inference Time (ms)</th>
              <th>Memory Usage (MB)</th>
              <th>Training Time (hours)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>TransGPT-XT<br/>GigaBERT Prime</td>
              <td>96.3<br/>94.7</td>
              <td>8.2<br/>9.5</td>
              <td>1200<br/>1100</td>
              <td>36<br/>48</td>
            </tr>
            <tr>
              <td>MegaLSTM-Pro<br/>UltraTransformer</td>
              <td>92.5<br/>97.1</td>
              <td>10.1<br/>7.8</td>
              <td>1050<br/>1300</td>
              <td>56<br/>42</td>
            </tr>
            <tr class="uk-active">
              <td>QuantumDNN-ALPHA</td>
              <td>95.8</td>
              <td>8.5</td>
              <td>1250</td>
              <td>50</td>
            </tr>
          </tbody>
        </table>
      </div>
projects: # relevant projects
  - title: Learning Direction Fields for Quad Mesh Generation
    description: Alexander Dielen, Isaak Lim, Max Lyon, Leif Kobbelt
    journal: "Eurographics Symposium on Geometry Processing 2021"
    url: https://www.graphics.rwth-aachen.de/publication/03337/
